+++
Categories = ["Computation", "Learning"]
bibfile = "ccnlab.json"
+++

The **bias-variance tradeoff**, also known as the "no free lunch" principle, was articulated by statisticians [[@^GemanGeman84]] and [[@^VapnikChervonenkis71]] among others. It is a critical principle that applies generally to any learning system.

The core idea is that when you don't have much data, you need to make up for that lack of data with stronger _biases_, which are a-priori assumptions built into your learning system that shape its behavior in particular ways, independent of whatever data it is being trained on. _If_ these biases are appropriate for the actual world in which the learning system is being trained on, then clearly they will be beneficial. However, the "no free lunch" part of the tradeoff is that there are no _universally beneficial biases_: every bias you introduce is beneficial for some worlds, but harmful for other possible worlds.

The _variance_ aspect of the tradeoff is a way of capturing the consequences of weakly biased learning systems: if you have weak biases, there will be correspondingly greater variance in what these systems learn given a fixed amount of training data. This variance will be manifest for example in the behavior of the system when confronted with novel testing data: each instance of a weakly-biased model will behave in a very different way (i.e., high variance), relative to a more strongly biased model, which will exhibit less bias and essentially always behave according to its biases.

One important implication of this tradeoff is that, if you do happen to have a large amount of data, it is generally better to use weakly biased, general-purpose learning systems, because the biases are unnecessary and can only get in your way (no free lunch). This _big data_ mantra is articulated in Rich Sutton's [bitter lesson](http://www.incompleteideas.net/IncIdeas/BitterLesson.html) for example. Existing [[abstract neural network]] (ANN) models have shown that this big data approach is very powerful, provided you can find a way to leverage large amounts of data.

In the biological domain that we are focused on here, the implications of this tradeoff are not so clear. First, biological organisms are only concerned with one world: the actual one in which they must survive. Second, the process of evolution provides a ready mechanism for building in all manner of biases that are specifically adaptive for this "real world" environment. Indeed, evolution can be considered a very general purpose "outer loop" adaptive (learning) mechanism that operates on a _huge_ amount of data, in the form of all the life-and-death struggles by generations of organisms across the globe, across the 3.5 odd billion or so years of life on earth. Each individual organism is just a brief inner-loop within the scope of this outer-loop of learning / adaptation.

In any case, it seems likely that data is a relatively precious commodity for real-world organisms, many of which come out of the egg or womb with very impressive _precocious_ abilities, like the ability to locomote in complex natural environments. Being able to survive with minimal data exposure is clearly a useful adaptive trait. Thus, overall, individual animals in their own _ontogeny_ (lifetimes) seem like they are the opposite of the big-data approach, and are instead strongly biased.

Except that humans are notoriously lacking in early precocial abilities. We come out of the womb with virtually no skills whatsoever, and it takes somewhere around 2-3 years to even learn to control our bowels properly! Thus, it seems that the human case may be more aligned with the general purpose learning approach. Nevertheless, when you consider all that people can learn to do within a couple of years (aside from bowel control), including learning to speak and toddle around without the benefit of strong pre-wired circuits for this, relative to the amount of actual life experience (data) over that time frame, it is likely that we do have some strong pre-wired biases, along with powerful general-purpose learning mechanisms.

The [[Rubicon]] framework provides a specific set of hypotheses about the nature of the strong pre-wired biases that we get from evolution, which supply us with complex systems of brain areas that drive goal-driven behavior according to evolutionarily-specified basic drives and motivations. Nevertheless, this system is all about learning novel plans and strategies for adaptive behavior and cognition, so the story is one of an intricate interplay between nature (bias) and nurture (data).

