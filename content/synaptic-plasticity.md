+++
Categories = ["Axon", "Learning"]
bibfile = "ccnlab.json"
+++

Synaptic plasticity is the well-established biological phenomenon that the strength of synaptic connections (i.e., _weights_) change in strength, which is known to be the primary basis for **learning** in the brain, consistent with the foundational hypothesis of [[abstract neural network]] models: _knowledge is encoded in synaptic weights_.

* **LTP = long-term potentiation** is the name for the phenomenon of persistent _increases_ in synaptic strength as a result of neural activity, as initially established by [[@^BlissLomo73]].

* **LTD = long-term depression** refers to _decreases_ in synaptic strength, which took a while longer to establish ([[@BearMalenka94]]).

Uncovering the biochemical basis for these phenomena has been one of the most successful collective research projects in neuroscience, resulting in a detailed understanding of many of the pathways and processes involved, which unfold over many different time scales as we briefly review here.

In an ideal world, the result of this effort would be a complete bottom-up grounding of the _functional_ nature of learning in the [[neocortex]]: we should be able derive the _learning algorithm_ at an algorithmic and computational [[levels of analysis|level of analysis]] based on a full understanding of the underlying hardware.

Existing attempts to derive this learning algorithm from the underlying neurobiological mechanisms center around the principles of [[Hebbian learning]], which were presciently described by Donald Hebb ([[@Hebb49]]). The core idea here is captured in the saying: _neurons that fire together, wire together_. In other words, Hebbian learning is an _associative_ form of learning that builds connections among neurons that are somehow related to each other, to the extent that their patterns of neural activity co-occur in time. The resulting networks of associations seem like they would provide a suitable basis for our subjective conceptual understanding of the world: e.g., when we see smoke, we associate the concept of fire, and can therefore make useful inferences.

The phenomenon of [[#spike timing dependent plasticity]] (STDP) ([[@BiPoo98]]) added a further nuance to the Hebbian idea and provides an elegant integration of both LTP and LTD in one coherent framework: neurons are apparently also sensitive to the temporal order of firing, strengthening associations (LTP) if the presynaptic neuron fires before the postsynaptic one, and weakening associations (LTD) in the converse situation. Intuitively, this allows neurons to learn a _causal_ kind of association, if these timing relationships represent a causal ordering, which is not very likely as discussed below. Furthermore, the STDP phenomenon arises in highly specific, artificial conditions that do not generalize to the more naturalistic patterns of neural activity in the awake, behaving state ([[in activo]]).

As discussed in [[Hebbian learning]], this associative learning principle (even in the STDP version of it) does not have a mathematical or computational foundation supporting the idea that it should result in an effective overall organization of a deep layered network of neurons, capable of accomplishing the cognitive functions of the [[neocortex]]. All of these considerations lead us to conclude that Hebbian learning fails to provide a complete computational description of what the synaptic plasticity mechanisms are doing. 

Instead, we argue that a different temporal dynamic (vs STDP) is critical for providing a coherent computational-level description of synaptic plasticity that implements [[error-driven learning]] in a way that is consistent with [[predictive learning]]. Unlike Hebbian learning, error-driven learning provides the well-established basis for all of the modern [[abstract neural network]] models powering the current [[artificial intelligence]] (AI) advances, so we know it works at a computational level. Furthermore, the predictive learning framework captures much of the same intuitive understanding as the Hebbian associative learning framework: a major driver of learning in the neocortex is to predict what will happen next, which is another way of thinking about the smoke-fire associative learning example.

The critical temporal dynamic needed to implement error-driven learning using known synaptic plasticity mechanisms is the [[temporal derivative]], which can be computed via a competitive interaction between two processes that integrate neural activity with different [[time constant]]s. This is the basis for the [[kinase algorithm]] used in [[Axon]], which is named for the competitive interaction between two _kinases_ that determine the direction of synaptic plasticity (LTP vs LTD) ([[@GoodellZaegelCoultrapEtAl17]]). This algorithm builds on all of the mechanisms described below.

## Synaptic plasticity mechanisms

{id="figure_ltp-nmda" style="height:25em"}
![Critical steps in allowing calcium ions (Ca++) to enter postsynaptic cell via NMDA channels, inducing synaptic plasticity. 1. The postsynaptic membrane potential (Vm) must be elevated (from excitatory inputs to AMPA receptors across synapses of the postsynaptic neuron, and backpropagating action potential that comes back down the dendrite when the postsynaptic neuron fires). 2. Elevated Vm causes magnesium (Mg++) ions to be expelled from NMDA channel openings, thus unblocking them. 3. Presynaptic neuron fires an action potential, releasing glutamate. 4. Glutamate binds to NMDA receptors, causing them to open, allowing Ca++ to enter (only when also unblocked, per step 2). 5. The concentration of Ca++ in the postsynaptic spine drives second messenger systems (indicated by the X) that result in changes in AMPA receptor number and efficacy, thereby changing the synaptic weight. Ca++ can also enter from voltage-gated calcium channels (VGCCs), which depend only on postsynaptic Vm levels, and not sending activity --- these are weaker contributors to Ca++ levels.](media/fig_ltpd_synapse.png)

The synapse has a lot of moving parts (introduced in [[neuron]]), any one of which could potentially be the critical factor in causing its overall efficacy to change. How many can you think of? The search for the critical factor(s) dominated the early phase of research on synaptic plasticity, and evidence for the involvement of a range of different factors has been found over the years, from the amount of presynaptic neurotransmitter released, to number and efficacy of postsynaptic AMPA receptors, and even more subtle things such as the alignment of pre and postsynaptic components, and more dramatic changes such as the cloning of multiple synapses. However, the dominant factor for long-lasting learning changes appears to be the number and efficacy of postsynaptic AMPA receptors.

[[#figure_ltp-nmda]] shows the five critical steps in the cascade of events that drives change in AMPA receptor efficacy. The [[neuron channels#NMDA|NMDA]] receptors and the calcium ion ($Ca^{++}$) play a central role. NMDA channels allow $Ca^{++}$ to enter the postsynaptic spine. Across all cells in the body, $Ca^{++}$ typically plays an important role in regulating cellular function, and in the neuron, it is capable of setting off a series of chemical reactions that ends up controlling how many AMPA receptors are functional in the synapse. For details on these reactions, see [[#Biochemical cascades of kinases and phosphatases]]. Here's what it takes for the $Ca^{++}$ to get into the postsynaptic cell:

1. The postsynaptic membrane potential ($V_m$) must be elevated, as a result of all the excitatory synaptic inputs coming into the cell. The most important contributor to this $V_m$ level is actually the **backpropagating action potential** --- when a neuron fires an action potential, it not only goes forward out the axon, but also backward down the dendrites (via active voltage-sensitive $Na^+$ channels along the dendrites). Thus, the entire neuron gets to know when it fires --- we'll see that this is incredibly useful computationally.

2. The elevated $V_m$ causes magnesium ions ($Mg^{++}$) to be repelled (positive charges repel each other) out of the openings of NMDA channels, unblocking them.

3. The presynaptic neuron fires an action potential, releasing glutamate neurotransmitter into the synaptic cleft.

4. Glutamate binds to the NMDA receptor, opening it to allow $Ca^{++}$ ions to flow into the postsynaptic cell. This only occurs if the NMDA is also unblocked. This dependence of NMDA on both pre and postsynaptic activity was one of the early important clues to the nature of learning, as we see later.

5. The concentration of $Ca^{++}$ in the postsynaptic spine drives those complex chemical reactions that end up changing the number and efficacy of AMPA receptors. Because these AMPA receptors provide the primary excitatory input drive on the neuron, changing them changes the net excitatory effect of a presynaptic action potential on the postsynaptic neuron. This is what is meant by changing the synaptic efficacy, or _weight_. The number of active AMPA channels is changed by a _trafficking_ process that actively moves these channels between an internal "reserve" store and those that are embedded in the _postsynaptic density_ (PSD) and exposed to the synaptic cleft so that glutamate can bind to them.

The dependence of NMDA on having both pre and postsynaptic activity is essentially identical to the Hebbian learning principle ([[@LevySteward79]], [[@CollingridgeKehlMcLennan83]], [[@CollingridgeBliss87]]), which is why most neuroscientists naturally assumed this was the whole story ([[@Cooper05]]). It just seems like to much of a coincidence if this is not what is actually going on computationally. 

$Ca^{++}$ can also enter the postsynaptic cell via **voltage gated calcium channels** [[#neuron channels#VGCC|VGCC]] which are calcium channels that only open when the membrane potential is elevated. Unlike NMDA, however, they are _not_ sensitive to presynaptic neural activity --- they only depend on postsynaptic activity. This has important computational implications, as we discuss later. VGCCs contribute less to $Ca^{++}$ levels than NMDA, so NMDA is still the dominant player.

**Metabotropic glutamate receptors (mGlu)** also play an important role in synaptic plasticity. These receptors do not allow ions to flow across the membrane (i.e., they are not _ionotropic_), and instead they directly trigger chemical reactions when neurotransmitter binds to them. These chemical reactions can then modulate the changes in AMPA receptors triggered by $Ca^{++}$.

{id="figure_ltpd-ca"}
![Standard account (after Lisman, 1989) for the direction of synaptic plasticity (LTP = increase, LTD = decrease) as a function of Ca++ concentration in the postsynaptic spine (accumulated over several hundred milliseconds). Low levels of Ca++ cause LTD, while higher levels drive LTP. Threshold levels indicated by theta values represent levels where the function changes sign.](media/fig_ltp_ltd_ca2+.png)

For a long time, researchers focused mainly on LTP (which is generally easier to induce), but eventually they realized that both directions of synaptic plasticity are equally important for learning ([[@DunwiddieLynch78]]; [[@Lisman89]]; [[@BearMalenka94]]). [[#figure_ltpd-ca]] shows the standard model for how this direction of change depends on the overall level of $Ca^{++}$ in the postsynaptic spine, accumulated over a few hundreds of milliseconds at least. Low levels drive LTD, while high levels produce LTP ([[@Lisman89]]; [[@BearMalenka94]]).

Interestingly, the shape of the function in [[#figure_ltpd-ca]] is essentially identical to one developed for a version of [[Hebbian learning]] known as the [[Hebbian learning#BCM]] rule in reference to the author's initials ([[@BienenstockCooperMunro82]]). To understand how the NMDA mechanism can lead to both LTD and LTP in this manner, we need to dig a little bit deeper into the biochemical processes that take place after $Ca^{++}$ enters the dendritic spine.

The basic story from [[@^Lisman89]] is that a _kinase_ known as _CaMKII_ drives LTP, while a competing _phosphatase_ pathway known as _PP1_ drives LTD, and that the differential sensitivities of these two pathways to the influx of $Ca^{++}$ results in the shape of the curve shown in [[#figure_ltpd-ca]]. Specifically, PP1 is dominant at low calcium levels and thus drives LTD, while CaMKII dominates at higher levels and thus drives LTP as calcium levels increase. This original hypothesis has withstood the test of time, but additional pathways have been discovered as discussed below.

## Spike Timing Dependent Plasticity

{id="figure_stdp" style="height:20em"}
![Spike timing dependent plasticity demonstrated in terms of temporal offset of firing of pre and postsynaptic neurons. If post fires after pre (Delta t > 0, right side), then the weights go up, and otherwise (Delta t < 0, left side) they go down. This fits with a causal flow of information from pre to post. Reproduced from Bi and Poo (1998).](media/fig_stdp_bipoo98.png)

It is fair to say that the finding of spike-timing dependent plasticity (STDP) by [[@^BiPoo98]] has been the single most impactful experiment in the field since the original [[@^BlissLomo73]] finding, with more than 30,000 papers containing that term on [google scholar](https://scholar.google.com/scholar?q=%22spike+timing+dependent+plasticity%22) (in quotes!) and over 5,000 citations of the original paper. [[#figure_stdp]] shows the key result: synaptic learning seems to obey a simple, appealing _causality_ principle, such that LTP occurs when the presynaptic neuron fires before the postsynaptic one, and vice-versa for the opposite order. This intuitively appealing logic has proven especially attractive to a large number of computational modelers, who have extensively employed STDP-like mechanisms (e.g., [[@KheradpishehGanjtabeshThorpeEtAl18]]; [[@DiehlCook15]]).

A simple version of the causal argument suggests that if a given pre neuron actually played a role in driving the post neuron to fire, then it must necessarily have fired in advance of it, and according to the STDP results, its weights will increase in strength. Meanwhile, pre neurons that have no causal role in firing the postsynaptic cell will have their weights decreased.

The vast literature on STDP has since revealed a tremendous amount of variability in whether you get LTP, LTD, or neither, depending on many different variables ([[@DebanneInglebert23]]), including a dependency on the non-naturalistic calcium and magnesium concentrations used in the _in vitro_ experiments (see [[in activo]]). Furthermore, the original experiment required highly specific and artificial stimulation conditions involving single isolated pairs of spikes separated by a full second of no activity, with many repetitions of a given such timing pattern required to produce the STDP results.

Critically, when even slightly more complex spike trains were used, the results were not consistent with a simple application of the classical STDP plasticity function, and instead reveal considerable more complexity in the nature of the underlying mechanism ([[@FroemkeDan02]]; [[@FroemkeTsayRaadEtAl06]]; [[@UrakuboHondaFroemkeEtAl08]]). A similar conclusion was reached by [[@^ShouvalWangWittenberg10]], who argue that a version of the BCM ([[@BienenstockCooperMunro82]]) mechanism provides a better overall account. We replicate this conclusion using the biologically-detailed model of [[@^UrakuboHondaFroemkeEtAl08]] as described below and available for exploration in [[urakubo08 sim]]. In short, this work suggests that STDP is a special case consequence of the underlying synaptic plasticity mechanisms, rather than a good description of what they accomplish in general.

Finally, a consideration of the natural patterns of neural activity in the awake, behaving [[neocortex]] raises fundamental questions about the causal logic behind the STDP theory in the first place. Specifically, there is considerable persistent ongoing neural activity at all levels of the neocortex, which has been shown to strongly contextualize the responses of neurons to incoming stimuli, for example ([[@ArieliSterkinGrinvaldEtAl96]]). Thus, contrary to the strictly feedforward causal direction envisioned by models based on STDP, activity in the brain does not have a simple reliable causal arrow due to the extensive [[bidirectional connectivity]].

## Biochemical cascades of kinases and phosphatases

{id="figure_urakubo-chem"}
![Diagram of the chemical processes included in the Urakubo et al. (2008) model, which are driven by Ca++ influx from NMDA and VGCC receptors. Ca++ binds to Calmodulin (CaM) which then directly and indirectly binds to two key kinases: CaMKII and PKA. Opposing these kinases (shown in red) are three phospatases (shown in blue), CaN (calcineurin), PP1 (protein phospatase 1) and PP2A. Per the Lisman (1989) model, CaMKII drives LTP by promoting the insertion of AMPA receptors into the postsynaptic density (PSD) where they are active, and PP1 drives LTD by promoting the endocyctosis of AMPA receptors into an inactive reserve pool. Reproduced from Urakubo et al, 2008.](media/fig_urakubo08_chem.jpg)

To better understand how LTP and LTD work in the brain, we need to understand more about the complex biochemical cascades that are triggered by the influx of calcium into the postsynaptic spine. There are two major players here (in addition to the calcium itself):

* **Kinases** are protein structures that act as a _catalyst_ for promoting other chemical reactions. They are typically activated by the binding of other substances at specific binding sites. One primary instance is the **CaMKII** kinase (_calcium/calmodulin-dependent protein kinase 2_), which plays a central role in synaptic plasticity, and also happens to bind directly to the NMDA receptor. In general, kinases act to _phosphorylate_ other molecules, which typically results in _activating_ them. Phosporylation means adding a phosphate group (compounds involving $PO_4$), and you may remember from high school biology that _ATP_ is the energy carrier in cells, where the P in ATP is phosphate (_adenosine triphosphate_). Phosphate = energy or activation in a very general sense.

* **Phosphatases** play an opposing role to kinases: they act to dephosphorylate other molecules, and thus typically deactivate or inhibit them. **PP1** (_protein phosphatase 1_) is a major opponent to CaMKII, according to the standard LTP / LTD model of [[@^Lisman89]].

[[#figure_urakubo-chem]] shows a cascade of chemical processes that are triggered by $Ca^{++}$ influx via NMDA and VGCC receptors, which are included in the [[@^UrakuboHondaFroemkeEtAl08]] model. The cascade goes through _CaM_ (calcium calmodulin) which is the primary direct binding target for $Ca^{++}$, which then activates _CaN_ (calcineurin, a phosphatase), CaMKII, and AC1/8. The fact that CaMKII is directly activated by CaM, whereas PP1 is a few more steps downstream of CaM, creates a significant difference in their temporal dynamics, where CaMKII is activated more quickly and PP1 takes longer to activate. These dynamics are based on prior models based on detailed measurements of the underlying chemical processes ([[@BhallaIyengar99]]; [[@KurodaSchweighoferKawato01]]; [[@DoiKurodaMichikawaEtAl05]]).

{id="figure_urakubo-poisson-25-100"  style="height:20em"}
![Dynamics of CaMKII, PKA, and PP1 in the Urakubo et al. (2008) model, in response to 200 ms of Poisson random spike trains of 25hz (left) or 100hz (right) pre and post activity, with a 20s post-activity period where the slower chemical proceses and AMPA trafficking settle out. The 25hz activity results in LTD (endocytosis of AMPA receptors), driven by the higher sustained activity of PP1 relative to CaMKII. PKA does not get sufficiently active to inhibit the PP1 pathway. Also note the much longer activity of PP1 vs. CaMKII, which builds on the longer activation of CaN (not shown). In the 100hz case, the increased initial activity is sufficient to persistently activate CaMKII and results in LTP instead of LTD. Furthermore, PP1 ends up being inhibited via the strongly activated PKA pathway.](media/fig_urakubo08_poisson_25_100hz_camkii_pka_pp1.png)

[[#figure_urakubo-poisson-25-100]] shows the timecourses of CaMKII, PKA, and PP1 in our replication of the [[@^UrakuboHondaFroemkeEtAl08]] model, available at [[urakubo08 sim]]. You can see that PP1 has a longer overall timecourse for the 25Hz random activity case in the first figure, and it ends up out-competing the transient activity of CaMKII, thus resulting in LTD (endocytocis of AMPA receptors from the postsynaptic density, PSD). In the 100hz random activity case in the second figure, CaMKII is sufficiently activated initially to remain active over time, and the stronger activation of the PKA pathway via the higher levels of calcium and CaM activation ends up inhibiting the PP1 pathway. This results in LTP (expression of the AMPA receptors in the postsynaptic density).

{id="figure_urakubo-xcal" style="height:30em"}
![The overall behavior of the Urakubo et al. (2008) model in response to spike trains with different frequencies and durations is shown in the black mesh 3D plot, where the depth Z axis is duration of spiking in portions of a second (0-1), the X axis is receiver firing frequency in Hz, and the different plots show different sender firing frequencies. All of this data can be captured at a high level of accuracy (Pearson's r=0.894) with a simple piecewise-linear function of the total "synaptic activity" which is the product of sending and receiving firing rate times the duration. This function, shown at the bottom right and as applied to the data in the red mesh plots, has a qualitative BCM-like shape, although in a more linearized form, with moderate levels of Ca++ producing LTD and higher levels producing LTP.](media/fig_xcal_dwt_fun_urakubo_fit_full.png)

We further tested the extent to which this model replicates the BCM-like curve shown in [[#figure_ltpd-ca]], which is predicted by by the [[@Lisman89]] CaMKII vs PP1 model, by systematically probing with spike trains of different frequencies and durations. The results, shown in [[#figure_urakubo-xcal]], confirm that this model does exhibit BCM-like behavior across a wide range of activity parameters, with a simple linearized version of the BCM function capturing a high level of variance (r=0.894). You can replicate this data yourself in  [[urakubo08 sim]].

{id="figure_urakubo-stdp" style="height:20em"}
![The Urakubo et al. (2008) model also replicates the STDP results of Bi and Poo (1998) using the standard protocol of single pairwise spikes at 1s intervals. Obtaining this behavior from the model required modifying the effective decay (inactivation) constant of the NMDA channels, so that glutamate binding from presynaptic release (i.e., pre before post, in the causal direction) resulted in a significant reduction in the rate of inactivation relative to glutamate unbound NMDA channels. Thus, the pre-before post direction (right side of curve) had much higher levels of Ca++ influx due to the longer open time of the NMDA channels. The resulting level of Ca++ influx and CaM activation mirrored the Delta-Wt learning curve shown in the first panel. Consistent with earlier figures, PP1 drives LTD for post-before-pre timings (left side of the curve), but CaMKII and PKA dominate on the pre-then-post side.](media/fig_urakubo08_stdp_all.png)

The [[@^UrakuboHondaFroemkeEtAl08]] model can also replicate the [[@^BiPoo98]] STDP results as shown in [[#figure_urakubo-stdp]], but only with a very specific modification that directly supports the STDP phenomenon. Specifically, they implemented _allosteric_ dynamics where the binding of glutamate to the NMDA receptor alters its rate of inactivation by a factor of 100, going from 2.3 ms (unbound) to 230 ms (bound). This inactivation is driven by CaM binding, as a result of Calcium entry. Thus, if the presynaptic neuron fires first, then the glutamate binding to the NMDA receptor causes it to stay open significantly longer and allow a high LTP-level of calcium to enter. Conversely, if postsynaptic fires before presynaptic, the NMDA receptor has the much shorter inactivation time constant and only an LTD-level of calcium enters.

Although this hypothesized mechanism is supported by additional data, it is unclear if it can be considered a well established property of the NMDA channel (e.g., it is not mentioned specifically in a recent thorough review of the inactivation mechanisms of NMDA channels; [[@IacobucciPopescu24]]). This raises the question as to whether other mechanisms missing from the [[@^UrakuboHondaFroemkeEtAl08]] model may instead provide the relevant differentiator behind the STDP phenomenon. Nevertheless, even in the extensive additional results from the [[@^UrakuboHondaFroemkeEtAl08]] model on more complex versions of STDP-like paradigms, there is ample evidence that the simple causal STDP story does not provide an adequate explanation of the nature of synaptic plasticity, as we further argued previously.

TODO: DAPK1 as one missing mech

This overall dynamic of different pathways with different time constants competing with each other is the hypothesized mechanism for the [[temporal derivative]] mechanism that the [[kinase algorithm]] uses to implement [[error-driven learning]]. However, the specific chemical pathways and dynamics included in the [[@^UrakuboHondaFroemkeEtAl08]] are not sufficient to capture this hypothesized dynamic, which is supported empirically in terms of overall weight change dynamics by the results of [[Jiang et al 2025]]. Furthermore, we were unable to replicate one of the most standard ways of inducing LTD, using a long sequence of low-frequency stimulation ([[@BearMalenka94]]).

The Urakubo et al. (2008) model was constructed in a very "bottom up" fashion, by building in detailed chemical rate parameters and diffusion constants, etc, based on empirical measurements, for all of the major biological processes involved in synaptic plasticity.  Having built this model, they found that it did *not* capture the classic spike timing dependent plasticity (STDP) curve, when driven by the exact STDP pairwise induction protocol (see figure of this in the main chapter text).  However, by changing one aspect of the way the NMDA receptors function (adding what is known as an *allosteric* mechanism, where the NMDA receptor functions differently depending on binding by a substance called calmodulin), they were able to capture not only pairwise STDP, but also the weight changes that result from more complex patterns of spiking, in triplet and quadruplet experiments. Furthermore, they accurately capture the effects of changing the timing parameters on pairwise STDP experiments (e.g., interval between pairwise spikes, and number of repetitions thereof).

Thus, this model represents a remarkable bridge between detailed biological mechanisms, and the overall synaptic plasticity that results in actual experiments.  Either this is a fantastic coincidence, or this model has managed to capture a reasonable chunk of the critical mechanisms of synaptic plasticity.  We adopt the later view, and therefore leverage this model as a basis for our computational models described in the main chapter.

{id="figure_urakubo-fits" style="height:30em"}
![Fit of the Urakubo et al. (2008) model with a simple learning function driven by the product of the total sending and receiving neural activity (frequency of firing in Hertz (Hz) times duration of firing in milliseconds).  This simple linear function (called the ''XCAL dWt function'') can capture a considerable amount of the regularity present in the behavior of the Urakubo et al. (2008) model, with a correlation value of ''r=0.894''.  The top portion of the figure shows graphs of three different sending Hz, with the X (horizontal) axis being the receiving unit Hz, Z (depth) is the duration of activity in fractions of a second (.1 to 1), and Y (vertical) is net change in synaptic weight.  The black lines are the measured results from Urakubo et al. (2008), and the red are the values computed from the simple piecewise-linear function shown at the bottom of the figure.](media/fig_xcal_dwt_fun_urakubo_fit_full.png)

For the bottom-up derivation of XCAL, we systematically subjected the biologically detailed Urakubo et al. (2008) model to a range of different *pre* and *post* spike trains, with durations from 100 msec to a second, and spike rates from 10 to 100 Hz (Hertz or spikes per second).  We then tried to fit the pattern of weight changes that resulted using a  piecewise linear function of some form.  [[#figure_urakubo-fits]] shows the results. The resulting function is shown at the bottom of the figure --- if you compare with [@fig:fig-xcal-dwt-fun], you should see that this is essentially the qualitative shape of the function relating weight change to level of $Ca^{++}$.  The top part of the figure is probably too complex to parse very well, but you should get the general impression that the red lines (generated by the piecewise linear function) fit the black lines (data from the Urakubo et al. (2008) model) pretty well.  The correlation value of .894 represents a very good fit of the function to the data.

Thus, we are able to capture much of the incredible complexity of the Urakubo et al. (2008) model (and by extension, hopefully, the complexity of the actual synaptic plasticity mechanisms in the brain) using an extremely simple function.  This is a very powerful simplification.  But what does it mean?

First, the main input into this function is the *total synaptic activity* reflecting the firing rate and duration of activity of the sending and receiving neurons.  In mathematical terms for a rate-code model with sending activity rate x and receiving activity rate y, this would just be the "Hebbian" product we described above:

$$
\Delta w = f_{xcal} \left( x y, \theta_p\right)
$$

Where $f_{xcal}$ is the piecewise linear function shown in [[#figure_urakubo-fits]] or 4.4, which we can call the *XCAL dWt function*.  It also takes an additional dynamic parameter $\theta_p$, which determines the point at which it crosses over from negative to positive weight changes --- we'll discuss this at length in a moment.  Just for kicks, here is the mathematical expression of this function:

where $\theta_d = .1$ is a constant that determines the point where the function reverses back toward zero within the weight decrease regime --- this reversal point occurs at $\theta_p \theta_d$, so that it adapts according to the dynamic $\theta_p$ value.

As noted in the main chapter, the dependence of the NMDA channel on activity of both sending and receiving neurons can be summarized with this simple Hebbian product, and the level of $Ca^{++}$ is likely to reflect this value.  Thus, the XCAL dWt function makes very good sense in these terms: it reflects the qualitative nature of weight changes as a function of $Ca^{++}$ that has been established from empirical studies and postulated by other theoretical models for a long time.  When realistic spike trains with many spikes drive the complex synaptic plasticity mechanisms, this fundamental function emerges.

As a learning function, this basic XCAL dWt function has some advantages over a plain Hebbian function, while sharing its basic nature due to the "pre * post" term at its core.  For example, because of the shape of the dWt function, weights will go down as well as up, whereas the Hebbian function only causes weights to increase.  But it still has the problem that weights will increase without bound, and we'll see in the next section that some other top-down computationally-motivated modifications can result in a much more powerful form of learning.

## Beyond induction

To this point, we have focused exclusively on the mechanisms active at the _induction_ of synaptic changes, as a function of neural activity on both sides of the synapse. This is where the key properties of a learning algorithm are to be found. However, there has been extensive research on the longer timecourse of events that take place after this initial induction event, which also have important functional implications and are incorporated into our computational models.

### Transient vs permanent changes

Considerable work in the aquatic snail _Aplysia_ and other species revealed that without a genetically-dependent process taking place roughly 1 hour after the initial induction event, synaptic changes are largely transient. This protein-synthesis dependent aspect of plasticity involves building up the physical structure of the dendritic spine, which involves _actin_ protein filaments, which are also involved in skeletal muscles. Thus, the brain really is like a muscle at some level: strengthening memories is like pumping iron: use it or lose it! These actin fibers stabilize the AMPA receptors poking out into the synaptic cleft, among other things.

### Synaptic changes during sleep

At a slightly longer time scale, there are a number of different synaptic mechanisms at work during different phases of sleep, and sleep has been found to have interesting effects on memories, consistent with the operation of these mechanisms (cites).

For example, Gina Turrigiano and colleagues have discovered extensive evidence for mechanisms that adapt overall synaptic strengths so as to preserve a neuron's characteristic overall level of neural activity ([[@TorradoPachecoBottorffGaoEtAl21]]). We found that incorporating an implementation of this type of mechanism makes a significant improvement on the overall stability and efficacy of our models.

